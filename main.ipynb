{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e594da50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avulsion fracture: 123\n",
      "Comminuted fracture: 148\n",
      "Fracture Dislocation: 156\n",
      "Greenstick fracture: 122\n",
      "Hairline Fracture: 111\n",
      "Impacted fracture: 84\n",
      "Longitudinal fracture: 80\n",
      "Not Fractured: 4908\n",
      "Oblique fracture: 85\n",
      "Pathological fracture: 134\n",
      "Spiral Fracture: 86\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "base_folder_path = r'C:\\Users\\Meetp\\OneDrive\\Documents\\ComputerVision\\FinalProject\\bonebreak\\Bone Break Classification'\n",
    "image_types = ['jpg', 'png']\n",
    "\n",
    "for fracture_type in os.listdir(base_folder_path):\n",
    "    fracture_path = os.path.join(base_folder_path, fracture_type)\n",
    "    if os.path.isdir(fracture_path):\n",
    "        count = 0\n",
    "        for root, _, files in os.walk(fracture_path):\n",
    "            for file in files:\n",
    "                if any(file.lower().endswith(ext) for ext in image_types):\n",
    "                    count += 1\n",
    "        print(f\"{fracture_type}: {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7aa1b364",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratified/Balanced Sampling (During Training)\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import ImageFile\n",
    "\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "dataset = datasets.ImageFolder(base_folder_path, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51e9d19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "from collections import Counter\n",
    "import os\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "dataset = datasets.ImageFolder(base_folder_path, transform=transform)\n",
    "\n",
    "# Recalculate class counts\n",
    "targets = [label for _, label in dataset]\n",
    "class_counts = Counter(targets)\n",
    "num_samples = len(dataset)\n",
    "class_weights = {cls: num_samples / count for cls, count in class_counts.items()}\n",
    "sample_weights = [class_weights[label] for label in targets]\n",
    "\n",
    "sampler = WeightedRandomSampler(weights=sample_weights, num_samples=len(dataset), replacement=True)\n",
    "dataloader = DataLoader(dataset, batch_size=32, sampler=sampler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9cb81e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled class distribution:\n",
      "Class 0 (Avulsion fracture): 525 samples\n",
      "Class 1 (Comminuted fracture): 545 samples\n",
      "Class 2 (Fracture Dislocation): 591 samples\n",
      "Class 3 (Greenstick fracture): 532 samples\n",
      "Class 4 (Hairline Fracture): 570 samples\n",
      "Class 5 (Impacted fracture): 565 samples\n",
      "Class 6 (Longitudinal fracture): 523 samples\n",
      "Class 7 (Not Fractured): 548 samples\n",
      "Class 8 (Oblique fracture): 542 samples\n",
      "Class 9 (Pathological fracture): 562 samples\n",
      "Class 10 (Spiral Fracture): 534 samples\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "label_counts = Counter()\n",
    "\n",
    "# Iterate through the full dataloader once\n",
    "for _, labels in dataloader:\n",
    "    label_counts.update(labels.tolist())\n",
    "\n",
    "print(\"Sampled class distribution:\")\n",
    "for class_idx, count in sorted(label_counts.items()):\n",
    "    print(f\"Class {class_idx} ({dataset.classes[class_idx]}): {count} samples\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe5b19b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "\n",
    "class FractureClassifier(nn.Module):\n",
    "    def __init__(self, num_fracture_types=10):  # not counting \"not fractured\"\n",
    "        super(FractureClassifier, self).__init__()\n",
    "        self.base = resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "        in_features = self.base.fc.in_features\n",
    "        self.base.fc = nn.Identity()\n",
    "\n",
    "        # Head 1: Fracture or not (binary)\n",
    "        self.fracture_detect = nn.Linear(in_features, 2)\n",
    "\n",
    "        # Head 2: Type of fracture (multiclass)\n",
    "        self.fracture_type = nn.Linear(in_features, num_fracture_types)\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.base(x)\n",
    "        out1 = self.fracture_detect(features)  # Binary output\n",
    "        out2 = self.fracture_type(features)    # Multiclass output\n",
    "        return out1, out2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f3eb640",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels = []  # original labels from dataset (0 = Not Fractured, 1-10 = fracture types)\n",
    "\n",
    "binary_labels = [0 if label == 0 else 1 for label in all_labels]\n",
    "fracture_type_labels = [label - 1 if label > 0 else -1 for label in all_labels]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c69e6b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "loss_fn_binary = nn.CrossEntropyLoss()\n",
    "loss_fn_type = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea98854b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/25]: 100%|██████████| 189/189 [03:50<00:00,  1.22s/it, loss=0.174] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25, Loss: 156.7177, Binary Accuracy: 96.36%, Type Accuracy: 81.26%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [2/25]: 100%|██████████| 189/189 [03:48<00:00,  1.21s/it, loss=0.061] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/25, Loss: 11.0435, Binary Accuracy: 99.88%, Type Accuracy: 99.40%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [3/25]: 100%|██████████| 189/189 [03:54<00:00,  1.24s/it, loss=0.00693]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/25, Loss: 3.3406, Binary Accuracy: 100.00%, Type Accuracy: 99.84%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [4/25]: 100%|██████████| 189/189 [03:46<00:00,  1.20s/it, loss=0.0104] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/25, Loss: 2.1572, Binary Accuracy: 100.00%, Type Accuracy: 99.87%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [5/25]: 100%|██████████| 189/189 [03:46<00:00,  1.20s/it, loss=0.00305]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/25, Loss: 0.9147, Binary Accuracy: 100.00%, Type Accuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [6/25]: 100%|██████████| 189/189 [03:44<00:00,  1.19s/it, loss=0.00408] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/25, Loss: 0.5423, Binary Accuracy: 100.00%, Type Accuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [7/25]: 100%|██████████| 189/189 [03:43<00:00,  1.18s/it, loss=0.0125]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/25, Loss: 0.4173, Binary Accuracy: 100.00%, Type Accuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [8/25]: 100%|██████████| 189/189 [03:49<00:00,  1.21s/it, loss=0.00184] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/25, Loss: 0.3516, Binary Accuracy: 100.00%, Type Accuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [9/25]: 100%|██████████| 189/189 [03:44<00:00,  1.19s/it, loss=0.00245] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/25, Loss: 0.3303, Binary Accuracy: 100.00%, Type Accuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [10/25]: 100%|██████████| 189/189 [03:44<00:00,  1.19s/it, loss=0.00156] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/25, Loss: 0.2066, Binary Accuracy: 100.00%, Type Accuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [11/25]: 100%|██████████| 189/189 [03:46<00:00,  1.20s/it, loss=0.00159] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/25, Loss: 0.1645, Binary Accuracy: 100.00%, Type Accuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [12/25]: 100%|██████████| 189/189 [03:53<00:00,  1.24s/it, loss=0.0143] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/25, Loss: 46.9369, Binary Accuracy: 98.53%, Type Accuracy: 93.72%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [13/25]: 100%|██████████| 189/189 [03:47<00:00,  1.20s/it, loss=0.00698]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/25, Loss: 9.1098, Binary Accuracy: 99.85%, Type Accuracy: 99.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [14/25]: 100%|██████████| 189/189 [03:48<00:00,  1.21s/it, loss=0.00232] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/25, Loss: 1.2435, Binary Accuracy: 100.00%, Type Accuracy: 99.95%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [15/25]: 100%|██████████| 189/189 [03:45<00:00,  1.19s/it, loss=0.0028]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/25, Loss: 0.3998, Binary Accuracy: 100.00%, Type Accuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [16/25]: 100%|██████████| 189/189 [03:50<00:00,  1.22s/it, loss=0.000835]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/25, Loss: 0.2677, Binary Accuracy: 100.00%, Type Accuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [17/25]: 100%|██████████| 189/189 [03:45<00:00,  1.19s/it, loss=0.000678]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/25, Loss: 0.1866, Binary Accuracy: 100.00%, Type Accuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [18/25]: 100%|██████████| 189/189 [03:46<00:00,  1.20s/it, loss=0.00117] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/25, Loss: 0.1578, Binary Accuracy: 100.00%, Type Accuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [19/25]: 100%|██████████| 189/189 [03:46<00:00,  1.20s/it, loss=0.0017]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/25, Loss: 0.1232, Binary Accuracy: 100.00%, Type Accuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [20/25]: 100%|██████████| 189/189 [03:45<00:00,  1.19s/it, loss=0.00206] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/25, Loss: 0.1198, Binary Accuracy: 100.00%, Type Accuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [21/25]: 100%|██████████| 189/189 [03:46<00:00,  1.20s/it, loss=0.000884]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/25, Loss: 0.0866, Binary Accuracy: 100.00%, Type Accuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [22/25]: 100%|██████████| 189/189 [03:45<00:00,  1.19s/it, loss=0.000369]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/25, Loss: 0.0787, Binary Accuracy: 100.00%, Type Accuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [23/25]: 100%|██████████| 189/189 [03:45<00:00,  1.19s/it, loss=0.00106] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/25, Loss: 0.1210, Binary Accuracy: 100.00%, Type Accuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [24/25]: 100%|██████████| 189/189 [03:46<00:00,  1.20s/it, loss=0.000578]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/25, Loss: 0.0665, Binary Accuracy: 100.00%, Type Accuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [25/25]: 100%|██████████| 189/189 [03:45<00:00,  1.19s/it, loss=0.000297]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/25, Loss: 0.0572, Binary Accuracy: 100.00%, Type Accuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = FractureClassifier()\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "num_epochs = 25\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    correct_binary = 0\n",
    "    total_binary = 0\n",
    "    correct_type = 0\n",
    "    total_type = 0\n",
    "\n",
    "    model.train()\n",
    "    loop = tqdm(dataloader, leave=True)\n",
    "\n",
    "    for images, original_labels in loop:\n",
    "        images = images.to(device)\n",
    "        original_labels = original_labels.to(device)\n",
    "\n",
    "        # Your original label conversions\n",
    "        binary_labels = (original_labels != 0).long().to(device)    # Not Fractured = 0, Fractured = 1\n",
    "        type_labels = (original_labels - 1).long().to(device)       # Shift classes for type prediction\n",
    "\n",
    "        output1, output2 = model(images)\n",
    "\n",
    "        loss_binary = loss_fn_binary(output1, binary_labels)\n",
    "\n",
    "        # Mask: Only fractured images (binary = 1)\n",
    "        mask = binary_labels == 1\n",
    "        if mask.sum() > 0:\n",
    "            loss_type = loss_fn_type(output2[mask], type_labels[mask])\n",
    "            loss = loss_binary + loss_type\n",
    "        else:\n",
    "            loss = loss_binary\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Accuracy tracking\n",
    "        pred_binary = torch.argmax(output1, dim=1)\n",
    "        correct_binary += (pred_binary == binary_labels).sum().item()\n",
    "        total_binary += binary_labels.size(0)\n",
    "\n",
    "        if mask.sum() > 0:\n",
    "            pred_type = torch.argmax(output2[mask], dim=1)\n",
    "            correct_type += (pred_type == type_labels[mask]).sum().item()\n",
    "            total_type += mask.sum().item()\n",
    "\n",
    "        loop.set_description(f\"Epoch [{epoch+1}/{num_epochs}]\")\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "\n",
    "    binary_acc = 100 * correct_binary / total_binary\n",
    "    type_acc = 100 * correct_type / total_type if total_type > 0 else 0\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss:.4f}, Binary Accuracy: {binary_acc:.2f}%, Type Accuracy: {type_acc:.2f}%\")\n",
    "\n",
    "    # Save model after each epoch\n",
    "    torch.save(model.state_dict(), f\"model_epoch_{epoch+1}.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d807752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots for loss and accuracy\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "train_losses = [\n",
    "    156.7177, 11.0435, 3.3406, 2.1572, 0.9147, 0.5423, 0.4173, 0.3516, 0.3303, 0.2066,\n",
    "    0.1645, 46.9369, 9.1098, 1.2435, 0.3998, 0.2677, 0.1866, 0.1578, 0.1232, 0.1198,\n",
    "    0.0866, 0.0787, 0.1210, 0.0665, 0.0572\n",
    "]\n",
    "\n",
    "train_binary_accuracies = [\n",
    "    96.36, 99.88, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0,\n",
    "    100.0, 98.53, 99.85, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0,\n",
    "    100.0, 100.0, 100.0, 100.0, 100.0\n",
    "]\n",
    "\n",
    "train_type_accuracies = [\n",
    "    81.26, 99.40, 99.84, 99.87, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0,\n",
    "    100.0, 93.72, 99.0, 99.95, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0,\n",
    "    100.0, 100.0, 100.0, 100.0, 100.0\n",
    "]\n",
    "\n",
    "epochs = list(range(1, 26))\n",
    "\n",
    "# --- Plot Loss ---\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(epochs, train_losses, label='Train Loss')\n",
    "plt.title('Training Loss vs. Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# --- Plot Binary Accuracy ---\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(epochs, train_binary_accuracies, label='Binary Accuracy', color='green')\n",
    "plt.title('Binary Fracture Detection Accuracy vs. Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# --- Plot Fracture Type Accuracy ---\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(epochs, train_type_accuracies, label='Fracture Type Accuracy', color='orange')\n",
    "plt.title('Fracture Type Classification Accuracy vs. Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
